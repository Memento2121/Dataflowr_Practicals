{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Memento2121/Dataflowr_Practicals/blob/main/prac_module_5_Stacking_layers_MLP_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV8M8LYLx3jB"
      },
      "source": [
        "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qvasKahx3jH"
      },
      "source": [
        "# [Module 5](https://dataflowr.github.io/website/modules/5-stacking-layers/): overfitting a MLP on CIFAR10\n",
        "\n",
        "Training loop over CIFAR10 (40,000 train images, 10,000 test images). What happens if you\n",
        "- switch the training to a GPU? Is it faster?\n",
        "- Remove the `ReLU()`?\n",
        "- Increase the learning rate?\n",
        "- Stack more layers?\n",
        "- Perform more epochs?\n",
        "\n",
        "Can you completely overfit the training set (i.e. get 100% accuracy?)\n",
        "\n",
        "This code is highly non-modulable. Create functions for each specific task.\n",
        "(hint: see [this](https://github.com/pytorch/examples/blob/master/mnist/main.py))\n",
        "\n",
        "Your training went well. Good. Why not save the weights of the network (`net.state_dict()`) using `torch.save()`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLXcxGCAx3jK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71722595-bc66-490e-bb4a-3cd7f2fa2e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 0\n",
            "Train loss 0.0358, Train accuracy 13.78%\n",
            "Train loss 0.0333, Train accuracy 24.72%\n",
            "Train loss 0.0321, Train accuracy 27.73%\n",
            "Train loss 0.0313, Train accuracy 29.81%\n",
            "Train loss 0.0306, Train accuracy 31.77%\n",
            "Train loss 0.0301, Train accuracy 32.96%\n",
            "Train loss 0.0297, Train accuracy 33.97%\n",
            "Train loss 0.0294, Train accuracy 34.69%\n",
            "Epoch 1\n",
            "Train loss 0.0261, Train accuracy 41.76%\n",
            "Train loss 0.0262, Train accuracy 41.12%\n",
            "Train loss 0.0263, Train accuracy 41.83%\n",
            "Train loss 0.0262, Train accuracy 42.01%\n",
            "Train loss 0.0260, Train accuracy 42.56%\n",
            "Train loss 0.0259, Train accuracy 42.71%\n",
            "Train loss 0.0258, Train accuracy 42.83%\n",
            "Train loss 0.0258, Train accuracy 42.84%\n",
            "Epoch 2\n",
            "Train loss 0.0244, Train accuracy 46.45%\n",
            "Train loss 0.0245, Train accuracy 45.14%\n",
            "Train loss 0.0246, Train accuracy 45.52%\n",
            "Train loss 0.0246, Train accuracy 45.48%\n",
            "Train loss 0.0244, Train accuracy 45.87%\n",
            "Train loss 0.0244, Train accuracy 45.95%\n",
            "Train loss 0.0244, Train accuracy 46.01%\n",
            "Train loss 0.0244, Train accuracy 45.97%\n",
            "End of training.\n",
            "\n",
            "End of testing. Test accuracy 46.18%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as t\n",
        "\n",
        "# define network structure\n",
        "net = nn.Sequential(nn.Linear(3 * 32 * 32, 1000), nn.ReLU(), nn.Linear(1000, 10))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr = 0.001, momentum=0.9)\n",
        "\n",
        "# load data\n",
        "to_tensor =  t.ToTensor()\n",
        "normalize = t.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "flatten =  t.Lambda(lambda x:x.view(-1))\n",
        "\n",
        "transform_list = t.Compose([to_tensor, normalize, flatten])\n",
        "train_set = torchvision.datasets.CIFAR10(root='.', train=True, transform=transform_list, download=True)\n",
        "test_set = torchvision.datasets.CIFAR10(root='.', train=False, transform=transform_list, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64)\n",
        "\n",
        "# === Train === ###\n",
        "net.train()\n",
        "\n",
        "# train loop\n",
        "for epoch in range(3):\n",
        "    train_correct = 0\n",
        "    train_loss = 0\n",
        "    print('Epoch {}'.format(epoch))\n",
        "\n",
        "    # loop per epoch\n",
        "    for i, (batch, targets) in enumerate(train_loader):\n",
        "\n",
        "        output = net(batch)\n",
        "        loss = criterion(output, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        train_correct += pred.eq(targets.view_as(pred)).sum().item()\n",
        "        train_loss += loss\n",
        "\n",
        "        if i % 100 == 10: print('Train loss {:.4f}, Train accuracy {:.2f}%'.format(\n",
        "            train_loss / ((i+1) * 64), 100 * train_correct / ((i+1) * 64)))\n",
        "\n",
        "print('End of training.\\n')\n",
        "\n",
        "# === Test === ###\n",
        "test_correct = 0\n",
        "net.eval()\n",
        "\n",
        "# loop, over whole test set\n",
        "for i, (batch, targets) in enumerate(test_loader):\n",
        "\n",
        "    output = net(batch)\n",
        "    pred = output.max(1, keepdim=True)[1]\n",
        "    test_correct += pred.eq(targets.view_as(pred)).sum().item()\n",
        "\n",
        "print('End of testing. Test accuracy {:.2f}%'.format(\n",
        "    100 * test_correct / (len(test_loader) * 64)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as t\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# define network structure\n",
        "class model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(3 * 32 * 32, 1000)\n",
        "    self.fc2 = nn.Linear(1000, 10)\n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "net = model().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr = 0.01)\n",
        "\n",
        "\n",
        "# load data\n",
        "to_tensor =  t.ToTensor()\n",
        "normalize = t.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "flatten =  t.Lambda(lambda x:x.view(-1))\n",
        "\n",
        "transform_list = t.Compose([to_tensor, normalize, flatten])\n",
        "train_set = torchvision.datasets.CIFAR10(root='.', train=True, transform=transform_list, download=True)\n",
        "test_set = torchvision.datasets.CIFAR10(root='.', train=False, transform=transform_list, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64)\n",
        "\n",
        "# === Train === ###\n",
        "net.train()\n",
        "\n",
        "# train loop\n",
        "for epoch in range(3):\n",
        "    train_correct = 0\n",
        "    train_loss = 0\n",
        "    print('Epoch {}'.format(epoch))\n",
        "\n",
        "    # loop per epoch\n",
        "    for i, (batch, targets) in enumerate(train_loader):\n",
        "        batch,targets = batch.to(device),targets.to(device)\n",
        "        output = net(batch)\n",
        "        loss = criterion(output, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        train_correct += pred.eq(targets.view_as(pred)).sum().item()\n",
        "        train_loss += loss\n",
        "\n",
        "        if i % 100 == 10: print('Train loss {:.4f}, Train accuracy {:.2f}%'.format(\n",
        "            train_loss / ((i+1) * 64), 100 * train_correct / ((i+1) * 64)))\n",
        "\n",
        "print('End of training.\\n')\n",
        "\n",
        "# === Test === ###\n",
        "test_correct = 0\n",
        "net.eval()\n",
        "\n",
        "# loop, over whole test set\n",
        "for i, (batch, targets) in enumerate(test_loader):\n",
        "    batch,targets = batch.to(device),targets.to(device)\n",
        "    output = net(batch)\n",
        "    pred = output.max(1, keepdim=True)[1]\n",
        "    test_correct += pred.eq(targets.view_as(pred)).sum().item()\n",
        "\n",
        "print('End of testing. Test accuracy {:.2f}%'.format(\n",
        "    100 * test_correct / (len(test_loader) * 64)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UEyM9dDU0O-",
        "outputId": "aca3b499-6dd2-48fe-98aa-25fcb055f8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 0\n",
            "Train loss 0.0364, Train accuracy 18.61%\n",
            "Train loss 0.0320, Train accuracy 29.31%\n",
            "Train loss 0.0306, Train accuracy 32.37%\n",
            "Train loss 0.0297, Train accuracy 34.37%\n",
            "Train loss 0.0289, Train accuracy 36.26%\n",
            "Train loss 0.0285, Train accuracy 37.01%\n",
            "Train loss 0.0282, Train accuracy 37.73%\n",
            "Train loss 0.0279, Train accuracy 38.33%\n",
            "Epoch 1\n",
            "Train loss 0.0250, Train accuracy 43.61%\n",
            "Train loss 0.0245, Train accuracy 45.71%\n",
            "Train loss 0.0243, Train accuracy 46.02%\n",
            "Train loss 0.0242, Train accuracy 46.45%\n",
            "Train loss 0.0239, Train accuracy 47.20%\n",
            "Train loss 0.0238, Train accuracy 47.26%\n",
            "Train loss 0.0238, Train accuracy 47.36%\n",
            "Train loss 0.0237, Train accuracy 47.42%\n",
            "Epoch 2\n",
            "Train loss 0.0222, Train accuracy 51.42%\n",
            "Train loss 0.0222, Train accuracy 51.15%\n",
            "Train loss 0.0221, Train accuracy 51.09%\n",
            "Train loss 0.0221, Train accuracy 51.38%\n",
            "Train loss 0.0218, Train accuracy 51.86%\n",
            "Train loss 0.0218, Train accuracy 51.87%\n",
            "Train loss 0.0218, Train accuracy 51.92%\n",
            "Train loss 0.0218, Train accuracy 51.96%\n",
            "End of training.\n",
            "\n",
            "End of testing. Test accuracy 42.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcpZfYmXx3jP"
      },
      "source": [
        "## Autograd tips and tricks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI6dD1j8x3jQ"
      },
      "source": [
        "Pointers are everywhere!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAUX3fsVx3jR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a269f32e-aa6e-4895-d97d-4757b3f60caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.2617,  0.6555],\n",
            "        [-0.0558, -0.2010]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.2622,  0.6462],\n",
            "        [-0.0563, -0.2103]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "net = nn.Linear(2, 2)\n",
        "w = net.weight\n",
        "print(w)\n",
        "\n",
        "x = torch.rand(1, 2)\n",
        "y = net(x).sum()\n",
        "y.backward()\n",
        "net.weight.data -= 0.01 * net.weight.grad # <--- What is this?\n",
        "print(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu6ro-5Qx3jS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ddcd7b-53b2-428a-9a1a-af632949e330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6454, -0.3360],\n",
            "        [-0.2955,  0.1087]], grad_fn=<CloneBackward0>)\n",
            "tensor([[-0.6454, -0.3360],\n",
            "        [-0.2955,  0.1087]], grad_fn=<CloneBackward0>)\n"
          ]
        }
      ],
      "source": [
        "net = nn.Linear(2, 2)\n",
        "w = net.weight.clone()\n",
        "print(w)\n",
        "\n",
        "x = torch.rand(1, 2)\n",
        "y = net(x).sum()\n",
        "y.backward()\n",
        "net.weight.data -= 0.01 * net.weight.grad # <--- What is this?\n",
        "print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHo85ov_x3jU"
      },
      "source": [
        "Sharing weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJEJhZItx3jU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f22899-2655-404f-8fe4-5a7b896d40db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0636, -1.1708],\n",
            "        [-1.5021, -1.6026]])\n",
            "tensor([[-1.0636, -1.1708],\n",
            "        [-1.5021, -1.6026]])\n"
          ]
        }
      ],
      "source": [
        "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
        "net[0].weight = net[1].weight  # weight sharing\n",
        "\n",
        "x = torch.rand(1, 2)\n",
        "y = net(x).sum()\n",
        "y.backward()\n",
        "print(net[0].weight.grad)\n",
        "print(net[1].weight.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y95mmHbXx3jV"
      },
      "source": [
        "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WibS3HEEx3jW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}